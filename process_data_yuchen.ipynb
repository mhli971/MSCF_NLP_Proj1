{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Yuchy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Fin-Neg Dictionary\n",
    "dict_csv = pd.read_csv(\n",
    "    'c:/Users/Yuchy/OneDrive/桌面/NLP/Assignment 1/Data/Loughran-McDonald_MasterDictionary_1993-2021.csv')\n",
    "dict_csv = dict_csv.query('Negative > 0')['Word']\n",
    "Fin_Neg = dict_csv.to_list()\n",
    "Fin_Neg = [word.lower() for word in Fin_Neg]\n",
    "\n",
    "# Get the H4N-Inf Dictionary\n",
    "dict_txt = open(\n",
    "    'c:/Users/Yuchy/OneDrive/桌面/NLP/Assignment 1/Data/Harvard IV_Negative Word List_Inf.txt', \n",
    "    'r',\n",
    "    encoding='utf-8')\n",
    "H4N_Inf = dict_txt.read().split('\\n')\n",
    "H4N_Inf = [word.lower() for word in H4N_Inf]\n",
    "dict_txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multiple txt files\n",
    "path = 'c:/Users/Yuchy/OneDrive/桌面/NLP/Assignment 1/txt/'\n",
    "filenames = [f for f in listdir(path) if isfile(join(path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_process(filename, i):\n",
    "\n",
    "    # Read the txt file\n",
    "    text = open(\n",
    "        path + filename,\n",
    "        'r',\n",
    "        encoding='utf-8').read().lower()\n",
    "    text = re.findall('[a-z][a-z]+', text)  # only extract words with length > 1\n",
    "\n",
    "    # Remove the stopwords\n",
    "    StopWord = set(stopwords.words('english'))\n",
    "    text_final = [word for word in text if not word in StopWord]\n",
    "\n",
    "    # Lemmatize all the words\n",
    "    lem = WordNetLemmatizer()\n",
    "    text_final = [lem.lemmatize(word)\n",
    "                for word in text_final if len(word) > 1]\n",
    "    text.close()\n",
    "\n",
    "    # convert the list to string for tf-idf calculation\n",
    "    return ' '.join(text_final) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "txt_ls = []\n",
    "for filename in filenames:\n",
    "    #locals()['text' + str(i)] = \n",
    "    txt_ls.append(txt_process(filename, i))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Read the txt file\\ntext = open(\\n    'c:/Users/Yuchy/OneDrive/桌面/NLP/Assignment 1/txt/sample1.txt', \\n    'r',\\n    encoding='utf-8').read().lower()\\ntext = re.findall('[a-z][a-z]+', text) # only extract words with length > 1\\n\\n# Remove the stopwords\\nStopWord = set(stopwords.words('english'))\\ntext_final = [word for word in text if not word in StopWord]\\n\\n# Lemmatize all the words\\nlem = WordNetLemmatizer()\\ntext_final = [lem.lemmatize(word) for word in text_final if len(word) > 1]\\n\\n# Form bag-of-words\\nword_freq_Fin = {}  # Words Frequency in Fin-Neg Dictionary\\nword_freq_H4N = {}  # Words Frequency in H4N-Inf Dictionary\\nfor word in text_final:\\n    if word in Fin_Neg:\\n        cnt1 = word_freq_Fin.get(word, 0)\\n        word_freq_Fin[word] = cnt1 + 1\\n    if word in H4N_Inf:\\n        cnt2 = word_freq_H4N.get(word, 0)\\n        word_freq_H4N[word] = cnt2 + 1\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For individual file\n",
    "'''\n",
    "# Read the txt file\n",
    "text = open(\n",
    "    'c:/Users/Yuchy/OneDrive/桌面/NLP/Assignment 1/txt/sample1.txt', \n",
    "    'r',\n",
    "    encoding='utf-8').read().lower()\n",
    "text = re.findall('[a-z][a-z]+', text) # only extract words with length > 1\n",
    "\n",
    "# Remove the stopwords\n",
    "StopWord = set(stopwords.words('english'))\n",
    "text_final = [word for word in text if not word in StopWord]\n",
    "\n",
    "# Lemmatize all the words\n",
    "lem = WordNetLemmatizer()\n",
    "text_final = [lem.lemmatize(word) for word in text_final if len(word) > 1]\n",
    "\n",
    "# Form bag-of-words\n",
    "word_freq_Fin = {}  # Words Frequency in Fin-Neg Dictionary\n",
    "word_freq_H4N = {}  # Words Frequency in H4N-Inf Dictionary\n",
    "for word in text_final:\n",
    "    if word in Fin_Neg:\n",
    "        cnt1 = word_freq_Fin.get(word, 0)\n",
    "        word_freq_Fin[word] = cnt1 + 1\n",
    "    if word in H4N_Inf:\n",
    "        cnt2 = word_freq_H4N.get(word, 0)\n",
    "        word_freq_H4N[word] = cnt2 + 1\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaa</th>\n",
       "      <th>aaaaamember</th>\n",
       "      <th>aaaandaaminuscreditratingmember</th>\n",
       "      <th>aaahc</th>\n",
       "      <th>aaalac</th>\n",
       "      <th>aaam</th>\n",
       "      <th>aab</th>\n",
       "      <th>...</th>\n",
       "      <th>zyprexamember</th>\n",
       "      <th>zyrtec</th>\n",
       "      <th>zytel</th>\n",
       "      <th>zytiga</th>\n",
       "      <th>zytigamember</th>\n",
       "      <th>zyvox</th>\n",
       "      <th>zyvoxmember</th>\n",
       "      <th>zz</th>\n",
       "      <th>zzau</th>\n",
       "      <th>zzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10446</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10447</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10448</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10449</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10450</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10451 rows × 121652 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        aa  aaa  aaaa  aaaaa  aaaaamember  aaaandaaminuscreditratingmember  \\\n",
       "0      0.0  0.0   0.0    0.0          0.0                              0.0   \n",
       "1      0.0  0.0   0.0    0.0          0.0                              0.0   \n",
       "2      0.0  0.0   0.0    0.0          0.0                              0.0   \n",
       "3      0.0  0.0   0.0    0.0          0.0                              0.0   \n",
       "4      0.0  0.0   0.0    0.0          0.0                              0.0   \n",
       "...    ...  ...   ...    ...          ...                              ...   \n",
       "10446  0.0  0.0   0.0    0.0          0.0                              0.0   \n",
       "10447  0.0  0.0   0.0    0.0          0.0                              0.0   \n",
       "10448  0.0  0.0   0.0    0.0          0.0                              0.0   \n",
       "10449  0.0  0.0   0.0    0.0          0.0                              0.0   \n",
       "10450  0.0  0.0   0.0    0.0          0.0                              0.0   \n",
       "\n",
       "       aaahc  aaalac  aaam  aab  ...  zyprexamember  zyrtec  zytel  zytiga  \\\n",
       "0        0.0     0.0   0.0  0.0  ...            0.0     0.0    0.0     0.0   \n",
       "1        0.0     0.0   0.0  0.0  ...            0.0     0.0    0.0     0.0   \n",
       "2        0.0     0.0   0.0  0.0  ...            0.0     0.0    0.0     0.0   \n",
       "3        0.0     0.0   0.0  0.0  ...            0.0     0.0    0.0     0.0   \n",
       "4        0.0     0.0   0.0  0.0  ...            0.0     0.0    0.0     0.0   \n",
       "...      ...     ...   ...  ...  ...            ...     ...    ...     ...   \n",
       "10446    0.0     0.0   0.0  0.0  ...            0.0     0.0    0.0     0.0   \n",
       "10447    0.0     0.0   0.0  0.0  ...            0.0     0.0    0.0     0.0   \n",
       "10448    0.0     0.0   0.0  0.0  ...            0.0     0.0    0.0     0.0   \n",
       "10449    0.0     0.0   0.0  0.0  ...            0.0     0.0    0.0     0.0   \n",
       "10450    0.0     0.0   0.0  0.0  ...            0.0     0.0    0.0     0.0   \n",
       "\n",
       "       zytigamember  zyvox  zyvoxmember   zz  zzau  zzz  \n",
       "0               0.0    0.0          0.0  0.0   0.0  0.0  \n",
       "1               0.0    0.0          0.0  0.0   0.0  0.0  \n",
       "2               0.0    0.0          0.0  0.0   0.0  0.0  \n",
       "3               0.0    0.0          0.0  0.0   0.0  0.0  \n",
       "4               0.0    0.0          0.0  0.0   0.0  0.0  \n",
       "...             ...    ...          ...  ...   ...  ...  \n",
       "10446           0.0    0.0          0.0  0.0   0.0  0.0  \n",
       "10447           0.0    0.0          0.0  0.0   0.0  0.0  \n",
       "10448           0.0    0.0          0.0  0.0   0.0  0.0  \n",
       "10449           0.0    0.0          0.0  0.0   0.0  0.0  \n",
       "10450           0.0    0.0          0.0  0.0   0.0  0.0  \n",
       "\n",
       "[10451 rows x 121652 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate tf-idf matrix\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(txt_ls)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense_ls = vectors.todense().tolist()\n",
    "tf_idf = pd.DataFrame(dense_ls, columns=feature_names)\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fin_neg_scores</th>\n",
       "      <th>h4n_inf_scores</th>\n",
       "      <th>cik</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035230</td>\n",
       "      <td>0.072861</td>\n",
       "      <td>1000228</td>\n",
       "      <td>2016-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.040757</td>\n",
       "      <td>0.077749</td>\n",
       "      <td>1000228</td>\n",
       "      <td>2016-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037062</td>\n",
       "      <td>0.077910</td>\n",
       "      <td>1000228</td>\n",
       "      <td>2016-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.035490</td>\n",
       "      <td>0.076647</td>\n",
       "      <td>1000228</td>\n",
       "      <td>2016-11-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034043</td>\n",
       "      <td>0.073779</td>\n",
       "      <td>1000228</td>\n",
       "      <td>2017-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10446</th>\n",
       "      <td>0.032713</td>\n",
       "      <td>0.069161</td>\n",
       "      <td>97745</td>\n",
       "      <td>2020-10-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10447</th>\n",
       "      <td>0.028968</td>\n",
       "      <td>0.070449</td>\n",
       "      <td>97745</td>\n",
       "      <td>2021-02-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10448</th>\n",
       "      <td>0.021976</td>\n",
       "      <td>0.060618</td>\n",
       "      <td>97745</td>\n",
       "      <td>2021-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10449</th>\n",
       "      <td>0.021716</td>\n",
       "      <td>0.062845</td>\n",
       "      <td>97745</td>\n",
       "      <td>2021-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10450</th>\n",
       "      <td>0.021468</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>97745</td>\n",
       "      <td>2021-11-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10451 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fin_neg_scores  h4n_inf_scores      cik        date\n",
       "0            0.035230        0.072861  1000228  2016-02-10\n",
       "1            0.040757        0.077749  1000228  2016-05-03\n",
       "2            0.037062        0.077910  1000228  2016-08-04\n",
       "3            0.035490        0.076647  1000228  2016-11-02\n",
       "4            0.034043        0.073779  1000228  2017-02-21\n",
       "...               ...             ...      ...         ...\n",
       "10446        0.032713        0.069161    97745  2020-10-30\n",
       "10447        0.028968        0.070449    97745  2021-02-25\n",
       "10448        0.021976        0.060618    97745  2021-05-07\n",
       "10449        0.021716        0.062845    97745  2021-08-06\n",
       "10450        0.021468        0.063436    97745  2021-11-04\n",
       "\n",
       "[10451 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the proportion for each text\n",
    "fin_neg_cols = list(set(tf_idf.columns).intersection(Fin_Neg))\n",
    "h4n_inf_cols = list(set(tf_idf.columns).intersection(H4N_Inf))\n",
    "fin_neg_scores = tf_idf[fin_neg_cols].sum(axis=1) / tf_idf.sum(axis=1)\n",
    "h4n_inf_scores = tf_idf[h4n_inf_cols].sum(axis=1) / tf_idf.sum(axis=1)\n",
    "# fin_neg_scores = tf_idf[fin_neg_cols].sum(axis=1)\n",
    "# h4n_inf_scores = tf_idf[h4n_inf_cols].sum(axis=1)\n",
    "scores = pd.concat([fin_neg_scores, h4n_inf_scores], axis=1)\\\n",
    "    .rename(columns={0:'fin_neg_scores', 1:'h4n_inf_scores'})\n",
    "scores['cik'] = [re.split('[_.]', word)[0] for word in filenames]\n",
    "scores['date'] = [re.split('[_.]', word)[1] for word in filenames]\n",
    "scores.to_csv('tfidf_scores_test.csv')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the simple proportion of negative words for each text\n",
    "prop_fin_neg = []\n",
    "prop_h4n_inf = []\n",
    "null_file = []\n",
    "j = 0\n",
    "for txt in txt_ls:\n",
    "    txt_tmp = txt.split()\n",
    "    words_dict = Counter(txt_tmp)\n",
    "    \n",
    "    # print(sum(words_dict.values()))\n",
    "    try:\n",
    "        prop_fin_neg.append(sum(words_dict[item]\n",
    "                            for item in Fin_Neg) / sum(words_dict.values()))\n",
    "        prop_h4n_inf.append(sum(words_dict[item]\n",
    "                            for item in H4N_Inf) / sum(words_dict.values()))\n",
    "    except:\n",
    "        null_file.append(j)\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fin_neg_prop</th>\n",
       "      <th>h4n_inf_prop</th>\n",
       "      <th>cik</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026823</td>\n",
       "      <td>0.075888</td>\n",
       "      <td>1000228</td>\n",
       "      <td>2016-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028172</td>\n",
       "      <td>0.077426</td>\n",
       "      <td>1000228</td>\n",
       "      <td>2016-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025308</td>\n",
       "      <td>0.078255</td>\n",
       "      <td>1000228</td>\n",
       "      <td>2016-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.024473</td>\n",
       "      <td>0.077950</td>\n",
       "      <td>1000228</td>\n",
       "      <td>2016-11-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026553</td>\n",
       "      <td>0.077303</td>\n",
       "      <td>1000228</td>\n",
       "      <td>2017-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10265</th>\n",
       "      <td>0.024407</td>\n",
       "      <td>0.074973</td>\n",
       "      <td>97745</td>\n",
       "      <td>2020-10-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10266</th>\n",
       "      <td>0.024706</td>\n",
       "      <td>0.079725</td>\n",
       "      <td>97745</td>\n",
       "      <td>2021-02-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10267</th>\n",
       "      <td>0.019698</td>\n",
       "      <td>0.066303</td>\n",
       "      <td>97745</td>\n",
       "      <td>2021-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10268</th>\n",
       "      <td>0.019373</td>\n",
       "      <td>0.067353</td>\n",
       "      <td>97745</td>\n",
       "      <td>2021-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10269</th>\n",
       "      <td>0.019484</td>\n",
       "      <td>0.068545</td>\n",
       "      <td>97745</td>\n",
       "      <td>2021-11-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10270 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fin_neg_prop  h4n_inf_prop      cik        date\n",
       "0          0.026823      0.075888  1000228  2016-02-10\n",
       "1          0.028172      0.077426  1000228  2016-05-03\n",
       "2          0.025308      0.078255  1000228  2016-08-04\n",
       "3          0.024473      0.077950  1000228  2016-11-02\n",
       "4          0.026553      0.077303  1000228  2017-02-21\n",
       "...             ...           ...      ...         ...\n",
       "10265      0.024407      0.074973    97745  2020-10-30\n",
       "10266      0.024706      0.079725    97745  2021-02-25\n",
       "10267      0.019698      0.066303    97745  2021-05-07\n",
       "10268      0.019373      0.067353    97745  2021-08-06\n",
       "10269      0.019484      0.068545    97745  2021-11-04\n",
       "\n",
       "[10270 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "props = pd.DataFrame()\n",
    "mod_filenames = [item for item in filenames if item not in [\n",
    "    filenames[i] for i in null_file]]\n",
    "props['fin_neg_prop'] = prop_fin_neg\n",
    "props['h4n_inf_prop'] = prop_h4n_inf\n",
    "props['cik'] = [re.split('[_.]', word)[0] for word in mod_filenames]\n",
    "props['date'] = [re.split('[_.]', word)[1] for word in mod_filenames]\n",
    "props.to_csv('props_test.csv')\n",
    "props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd9465e55f271c4a8a58977c717a4e339207c90f5b1bce6ffda9256ae990dfc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
